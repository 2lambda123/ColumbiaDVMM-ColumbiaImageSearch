COMPOSE_HTTP_TIMEOUT=600

# Should be set to $(git rev-parse --show-toplevel)
#repo_path=/home/ubuntu/columbiaimagesearch
#repo_path=/srv/skaraman/ColumbiaImageSearch
repo_path=/Users/svebor/Documents/Workspace/CodeColumbia/MEMEX/ColumbiaImageSearch
indocker_repo_path=/home/ubuntu/memex/ColumbiaImageSearch

# General verbose level (0-6)
verbose=3

# HT data from HG
# Can we set that to HBase?
input_type=kafka

# Extraction type
extr_type=dlibface

# HBase settings
# (remote)
hbase_host=10.1.94.57
table_sha1infos=escorts_images_sha1_infos_from_ts_subsampled_newformat
table_updateinfos=escorts_images_updates_subsampled_newformat
batch_update_size=2048

# Searcher settings
# If you already have a model:
# docker cp ../../../data/index/dlib_feat_dlib_face_pca128_train200000 search_img_search_1:/data/index/
# docker cp ../../../data/index/dlib_feat_dlib_face_lopq_pca-pca128-subq256-M8-V2048_train2000000 search_img_search_1:/data/index/
# Could not load object from path: /data/index/dlib_feat_dlib_face_lopq_pca-pca128-subq256-M8-V2048_train200000
# check files ownership inside docker: 501 dialout can cause issues
# fix with:
# - chown root /data/index/dlib_feat_dlib_face_*
# - chgrp root /data/index/dlib_feat_dlib_face_*
search_conf_name=dlibface_legacy_test_lopqpca
model_type=lopq_pca
nb_train=2000000
nb_min_train=20000
nb_train_pca=200000
nb_min_train_pca=20000
lopq_pcadims=128
lopq_V=2048
lopq_M=8
lopq_subq=256
file_input=false
storer=local
reranking=true

# API settings
port_host=80
endpoint=cufacesearch